version: '3.8'

services:
  # HE-Graph-Embeddings API Service
  he-graph-api:
    build:
      context: .
      dockerfile: Dockerfile.prod
      target: production
    image: ghcr.io/danieleschmidt/he-graph-embeddings:latest
    container_name: he-graph-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - ENV=production
      - PYTHONPATH=/app/src
      - CUDA_VISIBLE_DEVICES=0,1,2,3
      - HE_GRAPH_REGION=${HE_GRAPH_REGION:-us-east-1}
      - HE_GRAPH_COMPLIANCE_FRAMEWORKS=${COMPLIANCE_FRAMEWORKS:-GDPR,CCPA,SOC2}
      - HE_GRAPH_LOG_LEVEL=${LOG_LEVEL:-INFO}
      - HE_GRAPH_ENABLE_MONITORING=true
      - HE_GRAPH_ENABLE_CACHING=true
      - HE_GRAPH_MAX_WORKERS=8
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./config/production.yaml:/app/config/production.yaml:ro
      - cuda-cache:/root/.nv
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      - redis
      - prometheus
      - grafana
    networks:
      - he-graph-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 32G
          cpus: '16'
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=1g

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: he-graph-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: >
      redis-server 
      --requirepass ${REDIS_PASSWORD:-changeme123}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 60 1000
    volumes:
      - redis-data:/data
    networks:
      - he-graph-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 3s
      retries: 5

  # Prometheus monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: he-graph-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - he-graph-network

  # Grafana dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: he-graph-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=redis-datasource,prometheus-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - he-graph-network
    depends_on:
      - prometheus

  # Nginx reverse proxy with SSL
  nginx:
    image: nginx:alpine
    container_name: he-graph-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx-logs:/var/log/nginx
    depends_on:
      - he-graph-api
    networks:
      - he-graph-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Log aggregation with Fluentd
  fluentd:
    image: fluent/fluentd:v1.14-debian
    container_name: he-graph-fluentd
    restart: unless-stopped
    ports:
      - "24224:24224"
    volumes:
      - ./logging/fluentd.conf:/fluentd/etc/fluent.conf:ro
      - fluentd-logs:/fluentd/log
      - ./logs:/var/log/he-graph:ro
    networks:
      - he-graph-network
    depends_on:
      - elasticsearch

  # Elasticsearch for log storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: he-graph-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - he-graph-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Security scanner (runs periodically)
  security-scanner:
    build:
      context: .
      dockerfile: Dockerfile.security
    image: he-graph-security-scanner:latest
    container_name: he-graph-security
    restart: "no"
    environment:
      - SCAN_TARGET=/app/src
      - SCAN_INTERVAL=86400  # 24 hours
      - OUTPUT_DIR=/app/security-reports
    volumes:
      - ./src:/app/src:ro
      - ./security-reports:/app/security-reports
      - ./config/security.yaml:/app/config/security.yaml:ro
    networks:
      - he-graph-network
    profiles:
      - security

  # Health check service
  healthcheck:
    image: alpine/curl:latest
    container_name: he-graph-healthcheck
    restart: unless-stopped
    command: |
      sh -c '
        while true; do
          echo "$(date): Running health checks..."
          
          # Check API health
          if curl -f http://he-graph-api:8000/health >/dev/null 2>&1; then
            echo "API: healthy"
          else
            echo "API: unhealthy"
          fi
          
          # Check Redis
          if nc -z redis 6379 >/dev/null 2>&1; then
            echo "Redis: healthy" 
          else
            echo "Redis: unhealthy"
          fi
          
          # Check Prometheus
          if curl -f http://prometheus:9090/-/healthy >/dev/null 2>&1; then
            echo "Prometheus: healthy"
          else
            echo "Prometheus: unhealthy"
          fi
          
          sleep 300  # Check every 5 minutes
        done
      '
    networks:
      - he-graph-network
    depends_on:
      - he-graph-api
      - redis
      - prometheus

  # Backup service
  backup:
    image: alpine:latest
    container_name: he-graph-backup
    restart: "no"
    environment:
      - BACKUP_RETENTION_DAYS=30
      - S3_BUCKET=${BACKUP_S3_BUCKET}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    volumes:
      - redis-data:/backup/redis:ro
      - prometheus-data:/backup/prometheus:ro
      - grafana-data:/backup/grafana:ro
      - ./logs:/backup/logs:ro
      - ./security-reports:/backup/security-reports:ro
    command: |
      sh -c '
        apk add --no-cache aws-cli tar gzip
        
        # Create backup archive
        BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
        BACKUP_FILE="/tmp/he-graph-backup-$BACKUP_DATE.tar.gz"
        
        echo "Creating backup archive: $BACKUP_FILE"
        tar -czf "$BACKUP_FILE" -C /backup .
        
        # Upload to S3 if configured
        if [ ! -z "$S3_BUCKET" ]; then
          echo "Uploading backup to S3: $S3_BUCKET"
          aws s3 cp "$BACKUP_FILE" "s3://$S3_BUCKET/he-graph-backups/"
        fi
        
        echo "Backup completed: $BACKUP_FILE"
      '
    networks:
      - he-graph-network
    profiles:
      - backup

volumes:
  redis-data:
    driver: local
  prometheus-data:
    driver: local  
  grafana-data:
    driver: local
  elasticsearch-data:
    driver: local
  nginx-logs:
    driver: local
  fluentd-logs:
    driver: local
  cuda-cache:
    driver: local

networks:
  he-graph-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16